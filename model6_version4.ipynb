{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04742f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization ,Flatten,Dense, Activation,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3ac620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "train_data = pd.read_csv(\"csvTrainImages 60k x 784.csv\")\n",
    "train_label= pd.read_csv(\"csvTrainLabel 60k x 1.csv\")\n",
    "\n",
    "test_data=pd.read_csv(\"csvTestImages 10k x 784.csv\")\n",
    "test_label=pd.read_csv(\"csvTestLabel 10k x 1.csv\")\n",
    "\n",
    "\n",
    "#Drop unwanted images \n",
    "with open(\"unwanted_train_images.txt\", \"rb\") as file:   \n",
    "    unwanted = pickle.load(file)\n",
    "    \n",
    "train_data.drop(unwanted, axis=0, inplace=True)\n",
    "train_label.drop(unwanted, axis=0, inplace=True)\n",
    "\n",
    "with open(\"unwanted_test_images.txt\", \"rb\") as file:   \n",
    "    unwanted = pickle.load(file)\n",
    "    \n",
    "test_data.drop(unwanted, axis=0, inplace=True)\n",
    "test_label.drop(unwanted, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "#prepare data for modeling\n",
    "x_train=np.array(train_data)\n",
    "x_test=np.array(test_data)\n",
    "\n",
    "y_train=np.array(train_label)\n",
    "y_test=np.array(test_label)\n",
    "\n",
    "fun = lambda row : row.reshape(28,28).transpose()\n",
    "\n",
    "def transform(arr):\n",
    "    arr=arr/255.0\n",
    "    return np.apply_along_axis(fun,1,arr)\n",
    "\n",
    "x_train=transform(x_train)\n",
    "x_test=transform(x_test)\n",
    "\n",
    "shuffle_ind=[i for i in range(x_train.shape[0])]\n",
    "shuffle(shuffle_ind)\n",
    "\n",
    "x_train=x_train[shuffle_ind]\n",
    "y_train=y_train[shuffle_ind]\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test=x_test.reshape(y_test.shape[0],28,28,1)\n",
    "\n",
    "y_train = np.array(pd.get_dummies(pd.DataFrame(y_train), columns=[0]))\n",
    "y_test =  np.array(pd.get_dummies(pd.DataFrame(y_test), columns=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc63963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_val,y_train, y_val=train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4ec3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience = 5,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.8,\n",
    "                                            min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7defd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_6():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (5,5), input_shape=(28, 28, 1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64,  (5,5) , padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.20))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3),padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64,  (3,3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.20))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb7ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "836/836 [==============================] - 186s 223ms/step - loss: 0.0767 - accuracy: 0.9774 - val_loss: 0.0158 - val_accuracy: 0.9953\n",
      "Epoch 2/80\n",
      "836/836 [==============================] - 181s 216ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0154 - val_accuracy: 0.9946\n",
      "Epoch 3/80\n",
      "836/836 [==============================] - 203s 243ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.0130 - val_accuracy: 0.9956\n",
      "Epoch 4/80\n",
      "836/836 [==============================] - 197s 236ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
      "Epoch 5/80\n",
      "836/836 [==============================] - 196s 234ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0124 - val_accuracy: 0.9966\n",
      "Epoch 6/80\n",
      "836/836 [==============================] - 197s 236ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0145 - val_accuracy: 0.9953\n",
      "Epoch 7/80\n",
      "836/836 [==============================] - 195s 233ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0109 - val_accuracy: 0.9955\n",
      "Epoch 8/80\n",
      "836/836 [==============================] - 188s 225ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0141 - val_accuracy: 0.9948s: 0.0086 - accuracy: \n",
      "Epoch 9/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "836/836 [==============================] - 180s 215ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0081 - val_accuracy: 0.9971\n",
      "Epoch 10/80\n",
      "836/836 [==============================] - 185s 221ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 11/80\n",
      "836/836 [==============================] - 177s 211ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 12/80\n",
      "836/836 [==============================] - 178s 213ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0055 - val_accuracy: 0.9981\n",
      "Epoch 13/80\n",
      "836/836 [==============================] - 181s 216ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0104 - val_accuracy: 0.9973\n",
      "Epoch 14/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "836/836 [==============================] - 178s 213ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "Epoch 15/80\n",
      "836/836 [==============================] - 161s 192ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 16/80\n",
      "836/836 [==============================] - 158s 188ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 17/80\n",
      "836/836 [==============================] - 159s 190ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 18/80\n",
      "836/836 [==============================] - 158s 189ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 19/80\n",
      "836/836 [==============================] - 162s 194ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 20/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "836/836 [==============================] - 157s 188ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 21/80\n",
      "836/836 [==============================] - 165s 198ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 22/80\n",
      "836/836 [==============================] - 165s 198ms/step - loss: 8.5560e-04 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 23/80\n",
      "836/836 [==============================] - 165s 197ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 24/80\n",
      "836/836 [==============================] - 153s 183ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 25/80\n",
      "836/836 [==============================] - 161s 192ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "Epoch 26/80\n",
      "836/836 [==============================] - 167s 200ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 27/80\n",
      "836/836 [==============================] - 160s 192ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 28/80\n",
      "836/836 [==============================] - 156s 186ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 29/80\n",
      "836/836 [==============================] - 155s 186ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0026 - val_accuracy: 0.9997\n",
      "Epoch 30/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "836/836 [==============================] - 163s 195ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 31/80\n",
      "836/836 [==============================] - 151s 181ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 32/80\n",
      "836/836 [==============================] - 174s 209ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 33/80\n",
      "836/836 [==============================] - 182s 218ms/step - loss: 8.4378e-04 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 34/80\n",
      "836/836 [==============================] - 178s 213ms/step - loss: 6.8569e-04 - accuracy: 0.9998 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 35/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 6.5051e-04 - accuracy: 0.9997\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "836/836 [==============================] - 183s 219ms/step - loss: 6.5051e-04 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 36/80\n",
      "836/836 [==============================] - 167s 200ms/step - loss: 4.7357e-04 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "Epoch 37/80\n",
      "836/836 [==============================] - 166s 199ms/step - loss: 5.6698e-04 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 38/80\n",
      "836/836 [==============================] - 170s 203ms/step - loss: 5.2335e-04 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 39/80\n",
      "836/836 [==============================] - 168s 201ms/step - loss: 6.3989e-04 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 40/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 7.2036e-04 - accuracy: 0.9998\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "836/836 [==============================] - 167s 199ms/step - loss: 7.2036e-04 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 41/80\n",
      "836/836 [==============================] - 165s 197ms/step - loss: 3.5677e-04 - accuracy: 0.9999 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 42/80\n",
      "836/836 [==============================] - 183s 219ms/step - loss: 2.9702e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 43/80\n",
      "836/836 [==============================] - 182s 218ms/step - loss: 1.0431e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 44/80\n",
      "836/836 [==============================] - 172s 205ms/step - loss: 3.0178e-04 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 45/80\n",
      "836/836 [==============================] - 173s 207ms/step - loss: 3.7590e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
      "Epoch 46/80\n",
      "836/836 [==============================] - 169s 202ms/step - loss: 5.3732e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 47/80\n",
      "836/836 [==============================] - 169s 203ms/step - loss: 3.0510e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 48/80\n",
      "836/836 [==============================] - 170s 204ms/step - loss: 4.1091e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9997\n",
      "Epoch 49/80\n",
      "836/836 [==============================] - 161s 193ms/step - loss: 3.7289e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
      "Epoch 50/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 1.7028e-04 - accuracy: 0.9999\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "836/836 [==============================] - 162s 194ms/step - loss: 1.7028e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "Epoch 51/80\n",
      "836/836 [==============================] - 155s 185ms/step - loss: 4.7284e-04 - accuracy: 0.9998 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 52/80\n",
      "836/836 [==============================] - 154s 184ms/step - loss: 2.6073e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9997\n",
      "Epoch 53/80\n",
      "836/836 [==============================] - 155s 185ms/step - loss: 8.0137e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 54/80\n",
      "836/836 [==============================] - 161s 193ms/step - loss: 1.1321e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 55/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 2.0873e-04 - accuracy: 0.9999\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "836/836 [==============================] - 159s 190ms/step - loss: 2.0873e-04 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9995\n",
      "Epoch 56/80\n",
      "836/836 [==============================] - 150s 180ms/step - loss: 2.1850e-04 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
      "Epoch 57/80\n",
      "836/836 [==============================] - 160s 191ms/step - loss: 1.9401e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
      "Epoch 58/80\n",
      "836/836 [==============================] - 155s 186ms/step - loss: 1.0670e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 59/80\n",
      "836/836 [==============================] - 162s 194ms/step - loss: 6.8075e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 60/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 1.6540e-04 - accuracy: 0.9999\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "836/836 [==============================] - 172s 206ms/step - loss: 1.6540e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 61/80\n",
      "836/836 [==============================] - 170s 204ms/step - loss: 3.0889e-04 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 62/80\n",
      "836/836 [==============================] - 169s 202ms/step - loss: 1.4295e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 63/80\n",
      "836/836 [==============================] - 168s 201ms/step - loss: 1.9972e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 64/80\n",
      "836/836 [==============================] - 173s 207ms/step - loss: 1.0990e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "Epoch 65/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 4.4406e-05 - accuracy: 1.0000\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "836/836 [==============================] - 187s 224ms/step - loss: 4.4406e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 66/80\n",
      "836/836 [==============================] - 202s 242ms/step - loss: 4.8444e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 67/80\n",
      "836/836 [==============================] - 200s 239ms/step - loss: 8.3275e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 68/80\n",
      "836/836 [==============================] - 194s 232ms/step - loss: 1.8437e-04 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 69/80\n",
      "836/836 [==============================] - 196s 234ms/step - loss: 5.6477e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 70/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 6.1184e-05 - accuracy: 1.0000\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "836/836 [==============================] - 195s 234ms/step - loss: 6.1184e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9997\n",
      "Epoch 71/80\n",
      "836/836 [==============================] - 198s 236ms/step - loss: 3.0870e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9997\n",
      "Epoch 72/80\n",
      "836/836 [==============================] - 176s 210ms/step - loss: 8.4288e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 73/80\n",
      "836/836 [==============================] - 151s 180ms/step - loss: 3.1985e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 74/80\n",
      "836/836 [==============================] - 154s 184ms/step - loss: 5.5323e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9997\n",
      "Epoch 75/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 3.5994e-05 - accuracy: 1.0000\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "836/836 [==============================] - 161s 193ms/step - loss: 3.5994e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9997\n",
      "Epoch 76/80\n",
      "836/836 [==============================] - 160s 191ms/step - loss: 2.2921e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9997\n",
      "Epoch 77/80\n",
      "836/836 [==============================] - 160s 191ms/step - loss: 3.9507e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9997\n",
      "Epoch 78/80\n",
      "836/836 [==============================] - 157s 188ms/step - loss: 1.9058e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9997\n",
      "Epoch 79/80\n",
      "836/836 [==============================] - 159s 190ms/step - loss: 1.9063e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9997\n",
      "Epoch 80/80\n",
      "836/836 [==============================] - ETA: 0s - loss: 6.2692e-05 - accuracy: 1.0000\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "836/836 [==============================] - 157s 188ms/step - loss: 6.2692e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
      "time=  13688.610593795776\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model6= model_6()\n",
    "hist1 = model6.fit(x=x_train, y=y_train, batch_size=64, epochs=80, validation_data=(x_val,y_val) ,callbacks=[learning_rate_reduction])\n",
    "print('time= ',time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbeaf177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 4s 14ms/step - loss: 0.0447 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04468304663896561, 0.9942708015441895]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c61519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(hist1.history).plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168d4c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zeina Abu Ruqaia\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Zeina Abu Ruqaia\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model6_5\\assets\n"
     ]
    }
   ],
   "source": [
    "model6.save('model6_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603899bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=tf.keras.models.load_model('model6_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0816e49",
   "metadata": {},
   "source": [
    "### The dataset here  is created by me to test the model and evaluate the chosen one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91539bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace= True)\n",
    "\n",
    "shuffle_ind=[i for i in range(data.shape[0])]\n",
    "shuffle(shuffle_ind)\n",
    "\n",
    "x= np.array(data.drop(columns='class', axis=1))\n",
    "y= np.array(data['class'])\n",
    "\n",
    "x=x.reshape(y.shape[0],28,28,1)\n",
    "y=np.array(pd.get_dummies(pd.DataFrame(y), columns=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66250363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5737 - accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5737398266792297, 0.8830715417861938]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27449922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839613471923596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(data['class'],model6.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82ba880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5737 - accuracy: 0.8831\n",
      "[0.5737398266792297, 0.8830715417861938]\n",
      "\n",
      "\n",
      "[[59  2  1  0  1  0  1  1  0  0]\n",
      " [ 1 29  1  0  0  0  0  1  1  0]\n",
      " [ 1  0 40  0  3  0  0  0  4  1]\n",
      " [ 0  1  0 42  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 53  0  0  0  0  0]\n",
      " [ 1  0  5  0  3 48  0  7  1  0]\n",
      " [ 0  3  1  0  0  0 65  4  5  0]\n",
      " [ 0  0  0  0  0  0  0 62  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 52  0]\n",
      " [ 0  5  0  0  0  2  2  5  3 56]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        65\n",
      "           1       0.72      0.88      0.79        33\n",
      "           2       0.83      0.82      0.82        49\n",
      "           3       1.00      0.98      0.99        43\n",
      "           4       0.88      1.00      0.94        53\n",
      "           5       0.96      0.74      0.83        65\n",
      "           6       0.96      0.83      0.89        78\n",
      "           7       0.78      1.00      0.87        62\n",
      "           8       0.79      1.00      0.88        52\n",
      "           9       0.98      0.77      0.86        73\n",
      "\n",
      "    accuracy                           0.88       573\n",
      "   macro avg       0.89      0.89      0.88       573\n",
      "weighted avg       0.90      0.88      0.88       573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model6=tf.keras.models.load_model('model6_5')\n",
    "\n",
    "pred=np.argmax(model6.predict(x),axis=1)\n",
    "actual=np.argmax(y, axis=1)\n",
    "\n",
    "print(model6.evaluate(x,y))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "matrix = confusion_matrix(actual, pred)\n",
    "print(matrix)\n",
    "print()\n",
    "print()\n",
    "\n",
    "m1_report= classification_report(actual, pred)\n",
    "print(m1_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
